{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "batch_normalization.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasanth5reddy/D2L/blob/master/Modern%20Convolutional%20Networks/batch_normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqkGzZzwFnMP",
        "colab_type": "text"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbRJvNH9Evti",
        "colab_type": "code",
        "outputId": "f389b5c4-5ffd-4593-ba51-e331b3905f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "w_dir = '/content/drive/My Drive/Colab/D2L.AI/'\n",
        "sys.path.append(w_dir)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZyrYxwFFo-i",
        "colab_type": "text"
      },
      "source": [
        "Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDVS3KerFmyR",
        "colab_type": "code",
        "outputId": "30e0738c-3c4e-4c30-da79-43253c3b861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip uninstall mxnet && pip install mxnet-cu100"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping mxnet as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BvxtXeiFvU9",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGnldoYLF0hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet import autograd, gluon, init, nd\n",
        "from mxnet.gluon import nn\n",
        "import d2l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skd6oQdUUl8y",
        "colab_type": "text"
      },
      "source": [
        "Implementation from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PG2A6ipUj-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
        "  if not autograd.is_training():\n",
        "    X_hat = (X - moving_mean) / nd.sqrt(moving_var + eps)\n",
        "  else:\n",
        "    assert len(X.shape) in (2, 4)\n",
        "    if len(X.shape) == 2:\n",
        "      mean = X.mean(axis=0)\n",
        "      var = ((X - mean) ** 2).mean(axis=0)\n",
        "    else:\n",
        "      mean = X.mean(axis=(0, 2, 3), keepdims=True)\n",
        "      var = ((X - mean) ** 2).mean(axis=(0, 2, 3), keepdims=True)\n",
        "      \n",
        "    X_hat = (X - mean) / nd.sqrt(var + eps)\n",
        "    moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
        "    moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
        "    \n",
        "  Y = gamma * X_hat + beta\n",
        "  return Y, moving_mean, moving_var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFXFjGdYWYIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchNorm(nn.Block):\n",
        "  def __init__(self, num_features, num_dims, **kwargs):\n",
        "    super(BatchNorm, self).__init__(**kwargs)\n",
        "    if num_dims == 2:\n",
        "      shape = (1, num_features)\n",
        "    else:\n",
        "      shape = (1, num_features, 1, 1)\n",
        "      \n",
        "    self.gamma = self.params.get('gamma', shape=shape, init=init.One())\n",
        "    self.beta = self.params.get('beta', shape=shape, init=init.Zero())\n",
        "    \n",
        "    self.moving_mean = nd.zeros(shape)\n",
        "    self.moving_var = nd.zeros(shape)\n",
        "    \n",
        "  def forward(self, X):\n",
        "    if self.moving_mean.context != X.context:\n",
        "      self.moving_mean = self.moving_mean.copyto(X.context)\n",
        "      self.moving_var = self.moving_var.copyto(X.context)\n",
        "      \n",
        "    Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma.data(), self.beta.data(), self.moving_mean,\n",
        "                                                      self.moving_var, eps=1e-5, momentum=0.9)\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD7pUsqzhpE3",
        "colab_type": "text"
      },
      "source": [
        "Batch Normalization LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucSVOwsrYqdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nn.Conv2D(6, kernel_size=5),\n",
        "        BatchNorm(6, num_dims=4),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.MaxPool2D(pool_size=2, strides=2),\n",
        "        nn.Conv2D(16, kernel_size=5),\n",
        "        BatchNorm(16, num_dims=4),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.MaxPool2D(pool_size=2, strides=2),\n",
        "        nn.Dense(120),\n",
        "        BatchNorm(120, num_dims=2),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.Dense(84),\n",
        "        BatchNorm(84, num_dims=2),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5XIVRASh88v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8f95545e-e25e-48cb-85cb-97759b67ce8a"
      },
      "source": [
        "lr, num_epochs, batch_size, ctx = 1.0, 5, 256, d2l.try_gpu()\n",
        "net.initialize(ctx=ctx, init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
        "\n",
        "d2l.train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu(0)\n",
            "epoch 1, loss 0.6637, train acc 0.764, test acc 0.791, time 7.2 sec\n",
            "epoch 2, loss 0.4005, train acc 0.855, test acc 0.843, time 7.0 sec\n",
            "epoch 3, loss 0.3555, train acc 0.870, test acc 0.843, time 7.0 sec\n",
            "epoch 4, loss 0.3255, train acc 0.882, test acc 0.836, time 7.3 sec\n",
            "epoch 5, loss 0.3114, train acc 0.887, test acc 0.869, time 7.6 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1PPgQ-ViDlX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "df23246e-eee1-4dc0-9829-7ecd8be047fc"
      },
      "source": [
        "net[1].gamma.data().reshape((-1,)), net[1].beta.data().reshape((-1,))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\n",
              " [1.9808863  0.71188694 1.8091408  1.3103819  1.2874316  1.899171  ]\n",
              " <NDArray 6 @gpu(0)>, \n",
              " [ 0.910351    0.38128862 -0.07055879  0.38258594 -0.88927495 -2.020515  ]\n",
              " <NDArray 6 @gpu(0)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzJDiOm0ibg9",
        "colab_type": "text"
      },
      "source": [
        "Concise Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTlf-IliiZpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nn.Conv2D(6, kernel_size=5),\n",
        "        nn.BatchNorm(),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.MaxPool2D(pool_size=2, strides=2),\n",
        "        nn.Conv2D(16, kernel_size=5),\n",
        "        nn.BatchNorm(),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.MaxPool2D(pool_size=2, strides=2),\n",
        "        nn.Dense(120),\n",
        "        nn.BatchNorm(),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.Dense(84),\n",
        "        nn.BatchNorm(),\n",
        "        nn.Activation('sigmoid'),\n",
        "        nn.Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3pdozm4idLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "5b15e347-64a1-464e-e215-23af6eb4a546"
      },
      "source": [
        "net.initialize(ctx=ctx, init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "d2l.train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu(0)\n",
            "epoch 1, loss 0.6478, train acc 0.773, test acc 0.844, time 5.1 sec\n",
            "epoch 2, loss 0.3990, train acc 0.856, test acc 0.845, time 5.1 sec\n",
            "epoch 3, loss 0.3503, train acc 0.874, test acc 0.858, time 5.3 sec\n",
            "epoch 4, loss 0.3218, train acc 0.883, test acc 0.872, time 5.2 sec\n",
            "epoch 5, loss 0.3030, train acc 0.889, test acc 0.878, time 5.1 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}