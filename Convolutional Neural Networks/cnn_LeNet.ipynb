{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_LeNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prasanth5reddy/D2L/blob/master/Convolutional%20Neural%20Networks/cnn_LeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqkGzZzwFnMP",
        "colab_type": "text"
      },
      "source": [
        "Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbRJvNH9Evti",
        "colab_type": "code",
        "outputId": "bb6f3ca1-7714-441f-c611-6bd890d48976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "w_dir = '/content/drive/My Drive/Colab/D2L.AI/'\n",
        "sys.path.append(w_dir)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZyrYxwFFo-i",
        "colab_type": "text"
      },
      "source": [
        "Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDVS3KerFmyR",
        "colab_type": "code",
        "outputId": "f39003c8-abfc-4f75-f9ae-ed1309fe107f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip uninstall mxnet && pip install mxnet-cu100"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping mxnet as it is not installed.\u001b[0m\n",
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BvxtXeiFvU9",
        "colab_type": "text"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGnldoYLF0hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n",
        "import d2l\n",
        "from mxnet import autograd, nd, init, gluon\n",
        "from mxnet.gluon import loss as gloss, nn\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9smmUbg6zo4",
        "colab_type": "text"
      },
      "source": [
        "LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU8gKUzU6ylF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = nn.Sequential()\n",
        "net.add(nn.Conv2D(channels=6, kernel_size=5, padding=2, activation='sigmoid'),\n",
        "        nn.AvgPool2D(pool_size=2, strides=2),\n",
        "        nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n",
        "        nn.AvgPool2D(pool_size=2, strides=2),\n",
        "        # Dense will transform the input of the shape (batch size, channel, height, width) \n",
        "        # into the input of the shape (batch size, channel * height * width) automatically by default\n",
        "        nn.Dense(120, activation='sigmoid'),\n",
        "        nn.Dense(84, activation='sigmoid'),\n",
        "        nn.Dense(10))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNviweMg9KSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1439a1c9-c5ef-4dfe-aa7d-b19c3c303430"
      },
      "source": [
        "X = nd.random.uniform(shape=(1, 1, 28, 28))\n",
        "net.initialize()\n",
        "for layer in net:\n",
        "  X = layer(X)\n",
        "  print(layer.name, 'output shape:\\t', X.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv0 output shape:\t (1, 6, 28, 28)\n",
            "pool0 output shape:\t (1, 6, 14, 14)\n",
            "conv1 output shape:\t (1, 16, 10, 10)\n",
            "pool1 output shape:\t (1, 16, 5, 5)\n",
            "dense0 output shape:\t (1, 120)\n",
            "dense1 output shape:\t (1, 84)\n",
            "dense2 output shape:\t (1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dixB0dmpCX7f",
        "colab_type": "text"
      },
      "source": [
        "Data Acquisition and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlVNeuNw9eww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzSbYAzjCvm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f21aea25-bd11-4160-8a1d-0c07bb543b25"
      },
      "source": [
        "def try_gpu():\n",
        "  try:\n",
        "    ctx = mx.gpu()\n",
        "    _ = nd.array([1], ctx=ctx)\n",
        "  except mx.base.MXNetError:\n",
        "    ctx = mx.cpu()\n",
        "  return ctx\n",
        "\n",
        "ctx = try_gpu()\n",
        "ctx"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gpu(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X4kuxEdDGCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_accuracy(data_iter, net, ctx):\n",
        "  acc_sum, n = nd.array([0], ctx=ctx), 0\n",
        "  for X, y in data_iter:\n",
        "    X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n",
        "    acc_sum += (net(X).argmax(axis=1) == y).sum()\n",
        "    n += y.size\n",
        "  return acc_sum.asscalar() / n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZkTBYZ8GCIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs):\n",
        "  print('training on', ctx)\n",
        "  loss = gloss.SoftmaxCELoss()\n",
        "  for epoch in range(num_epochs):\n",
        "    train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "    for X, y in train_iter:\n",
        "      X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
        "      with autograd.record():\n",
        "        y_hat = net(X)\n",
        "        l = loss(y_hat, y).sum()\n",
        "      l.backward()\n",
        "      trainer.step(batch_size)\n",
        "      y = y.astype('float32')\n",
        "      train_l_sum += l.asscalar()\n",
        "      train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
        "      n += y.size\n",
        "    test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtbfOcqEIoPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "39c44038-95e7-46af-9388-dd89d655824d"
      },
      "source": [
        "lr, num_epochs = 0.9, 10\n",
        "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu(0)\n",
            "epoch 1, loss 2.3196, train acc 0.098, test acc 0.100, time 4.9 sec\n",
            "epoch 2, loss 2.2561, train acc 0.134, test acc 0.430, time 4.7 sec\n",
            "epoch 3, loss 1.1088, train acc 0.552, test acc 0.672, time 4.7 sec\n",
            "epoch 4, loss 0.8032, train acc 0.684, test acc 0.721, time 4.6 sec\n",
            "epoch 5, loss 0.6836, train acc 0.732, test acc 0.756, time 4.7 sec\n",
            "epoch 6, loss 0.6136, train acc 0.760, test acc 0.781, time 4.7 sec\n",
            "epoch 7, loss 0.5649, train acc 0.781, test acc 0.794, time 4.7 sec\n",
            "epoch 8, loss 0.5330, train acc 0.793, test acc 0.818, time 4.7 sec\n",
            "epoch 9, loss 0.4996, train acc 0.808, test acc 0.827, time 4.9 sec\n",
            "epoch 10, loss 0.4748, train acc 0.820, test acc 0.836, time 4.5 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXA0nEDHLE97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "256f22e7-e3e2-405a-b9c8-3419b1dd04d1"
      },
      "source": [
        "lr, num_epochs = 0.9, 5\n",
        "net.initialize(force_reinit=True, ctx=mx.cpu(), init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "train_ch5(net, train_iter, test_iter, batch_size, trainer, mx.cpu(), num_epochs)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on cpu(0)\n",
            "epoch 1, loss 2.3207, train acc 0.101, test acc 0.100, time 26.3 sec\n",
            "epoch 2, loss 2.1631, train acc 0.173, test acc 0.489, time 24.6 sec\n",
            "epoch 3, loss 1.0340, train acc 0.585, test acc 0.676, time 26.0 sec\n",
            "epoch 4, loss 0.8111, train acc 0.685, test acc 0.735, time 26.8 sec\n",
            "epoch 5, loss 0.6881, train acc 0.732, test acc 0.758, time 24.6 sec\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}